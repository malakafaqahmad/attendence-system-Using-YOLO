{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-24T16:56:36.887006Z",
     "iopub.status.busy": "2024-12-24T16:56:36.886091Z",
     "iopub.status.idle": "2024-12-24T16:56:46.992320Z",
     "shell.execute_reply": "2024-12-24T16:56:46.991267Z",
     "shell.execute_reply.started": "2024-12-24T16:56:36.886963Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Detection YOLO for Face Detection: Use YOLO to detect faces in the scene.Face Recognition for Identification: After detection, pass the cropped face regions to a face recognition model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T16:56:46.994372Z",
     "iopub.status.busy": "2024-12-24T16:56:46.994061Z",
     "iopub.status.idle": "2024-12-24T16:56:50.850725Z",
     "shell.execute_reply": "2024-12-24T16:56:50.850025Z",
     "shell.execute_reply.started": "2024-12-24T16:56:46.994345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T16:56:50.852035Z",
     "iopub.status.busy": "2024-12-24T16:56:50.851715Z",
     "iopub.status.idle": "2024-12-24T16:56:50.858157Z",
     "shell.execute_reply": "2024-12-24T16:56:50.857361Z",
     "shell.execute_reply.started": "2024-12-24T16:56:50.852010Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# from PIL import Image\n",
    "\n",
    "# # Define paths\n",
    "# train_images_dir = '/kaggle/input/attendence-dataset-for-dnn/Yolov8_label_images.v1i.yolov8/train/images'\n",
    "# train_labels_dir = '/kaggle/input/attendence-dataset-for-dnn/Yolov8_label_images.v1i.yolov8/train/labels'\n",
    "\n",
    "# # Select a random image and corresponding label file\n",
    "# image_files = [f for f in os.listdir(train_images_dir) if f.endswith('.jpg')]\n",
    "# random_image_file = random.choice(image_files)\n",
    "\n",
    "# image_path = os.path.join(train_images_dir, random_image_file)\n",
    "# label_path = os.path.join(train_labels_dir, random_image_file.replace('.jpg', '.txt'))\n",
    "\n",
    "# # Load image\n",
    "# image = Image.open(image_path)\n",
    "# image_width, image_height = image.size\n",
    "\n",
    "# # Load labels\n",
    "# annotations = []\n",
    "# if os.path.exists(label_path):\n",
    "#     with open(label_path, 'r') as f:\n",
    "#         for line in f:\n",
    "#             parts = line.strip().split()\n",
    "#             cls, x_center, y_center, width, height = map(float, parts)\n",
    "#             annotations.append((cls, x_center, y_center, width, height))\n",
    "\n",
    "# # Visualize the image with annotations\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "# ax.imshow(image)\n",
    "\n",
    "# # Draw bounding boxes\n",
    "# for cls, x_center, y_center, width, height in annotations:\n",
    "#     # Convert normalized coordinates to absolute pixel values\n",
    "#     abs_x = x_center * image_width\n",
    "#     abs_y = y_center * image_height\n",
    "#     abs_w = width * image_width\n",
    "#     abs_h = height * image_height\n",
    "\n",
    "#     # Top-left corner of the bounding box\n",
    "#     top_left_x = abs_x - abs_w / 2\n",
    "#     top_left_y = abs_y - abs_h / 2\n",
    "\n",
    "#     # Draw rectangle\n",
    "#     rect = patches.Rectangle(\n",
    "#         (top_left_x, top_left_y), abs_w, abs_h,\n",
    "#         linewidth=2, edgecolor='red', facecolor='none'\n",
    "#     )\n",
    "#     ax.add_patch(rect)\n",
    "\n",
    "#     # Add label text\n",
    "#     ax.text(\n",
    "#         top_left_x, top_left_y - 10, f\"Class: {int(cls)}\",\n",
    "#         color='red', fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5)\n",
    "#     )\n",
    "\n",
    "# ax.axis('off')\n",
    "# ax.set_title(f\"Image: {random_image_file} with Annotations\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Yolo v11 Model\n",
    "\n",
    "*Object detection is a task that involves identifying the location and class of objects in an image or video stream.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-24T16:56:50.861235Z",
     "iopub.status.busy": "2024-12-24T16:56:50.860619Z",
     "iopub.status.idle": "2024-12-24T16:59:36.549302Z",
     "shell.execute_reply": "2024-12-24T16:59:36.548343Z",
     "shell.execute_reply.started": "2024-12-24T16:56:50.861196Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11m.pt\")\n",
    "\n",
    "\n",
    "model.train(data='/kaggle/input/detection-dataset/detection dataset/data.yaml',\n",
    "            epochs=50,\n",
    "            imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:22:12.940216Z",
     "iopub.status.busy": "2024-12-24T17:22:12.939461Z",
     "iopub.status.idle": "2024-12-24T17:22:12.994267Z",
     "shell.execute_reply": "2024-12-24T17:22:12.993570Z",
     "shell.execute_reply.started": "2024-12-24T17:22:12.940183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('yolov11_finetuned_dtn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:25:29.779246Z",
     "iopub.status.busy": "2024-12-24T17:25:29.778576Z",
     "iopub.status.idle": "2024-12-24T17:25:30.000686Z",
     "shell.execute_reply": "2024-12-24T17:25:29.999894Z",
     "shell.execute_reply.started": "2024-12-24T17:25:29.779213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = YOLO('yolov11_finetuned_dtn.pt')\n",
    "\n",
    "# Input image path\n",
    "input_image_path = '/kaggle/input/attendence-dataset-for-dnn/Yolov8_label_images.v1i.yolov8/train/images/WhatsApp-Image-2024-12-06-at-12-19-02-PM-1-_jpeg.rf.105d4b1bbbc237f460826d2a18b318bd.jpg'  # Replace with your image path\n",
    "\n",
    "# Perform inference with a high confidence threshold\n",
    "results = model(input_image_path, conf=0.1)  # Set confidence threshold (e.g., 0.7)\n",
    "\n",
    "# Visualize and filter results\n",
    "result = results[0]  # Assuming 'results' is a list\n",
    "high_conf_detections = [detection for detection in result.boxes if detection.conf > 0.1]\n",
    "\n",
    "# Draw and save filtered detections\n",
    "if high_conf_detections:\n",
    "    annotated_image = result.plot()  # Visualize with detections\n",
    "    plt.imshow(annotated_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the image\n",
    "    save_path = 'high_conf_results.jpg'\n",
    "    cv2.imwrite(save_path, annotated_image)\n",
    "    print(f\"Filtered results saved to {save_path}\")\n",
    "else:\n",
    "    print(\"No detections with confidence above the threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:09:45.179613Z",
     "iopub.status.busy": "2024-12-24T17:09:45.179226Z",
     "iopub.status.idle": "2024-12-24T17:09:45.494250Z",
     "shell.execute_reply": "2024-12-24T17:09:45.493493Z",
     "shell.execute_reply.started": "2024-12-24T17:09:45.179583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fine-tuned face detection model (replace with your face-specific model)\n",
    "model = YOLO('yolov8n.pt')  # Ensure this model is trained to detect faces\n",
    "\n",
    "# Input image path\n",
    "input_image_path = '/kaggle/input/attendence-dataset-for-dnn/Yolov8_label_images.v1i.yolov8/train/images/WhatsApp-Image-2024-12-06-at-12-19-02-PM-1-_jpeg.rf.105d4b1bbbc237f460826d2a18b318bd.jpg'  # Replace with your image path\n",
    "\n",
    "# Perform inference with a high confidence threshold\n",
    "results = model(input_image_path, conf=0.6)  # Set confidence threshold\n",
    "\n",
    "# Visualize and filter results\n",
    "result = results[0]  # Assuming 'results' is a list\n",
    "\n",
    "# Filter detections for faces only (class index for \"face\" is assumed to be 0; adjust if needed)\n",
    "face_detections = [\n",
    "    detection for detection in result.boxes if detection.conf > 0.6 and detection.cls == 0\n",
    "]\n",
    "\n",
    "# Draw and save filtered face detections\n",
    "if face_detections:\n",
    "    annotated_image = result.plot()  # Visualize detections\n",
    "    plt.imshow(annotated_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the image\n",
    "    save_path = 'face_detections.jpg'\n",
    "    cv2.imwrite(save_path, annotated_image)\n",
    "    print(f\"Face detections saved to {save_path}\")\n",
    "else:\n",
    "    print(\"No face detections with confidence above the threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-24T16:59:37.543405Z",
     "iopub.status.idle": "2024-12-24T16:59:37.544166Z",
     "shell.execute_reply": "2024-12-24T16:59:37.543939Z",
     "shell.execute_reply.started": "2024-12-24T16:59:37.543913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = YOLO('yolov8_finetuned.pt')\n",
    "\n",
    "# Input image path\n",
    "input_image_path = '/kaggle/working/results_WhatsApp-Image-2024-12-14-at-11-49-17-PM-3-_jpeg.rf.9a136273f05e084ce5c78d8d95e6f94d.jpg'  # Replace with your image path\n",
    "\n",
    "# Perform inference\n",
    "results = model(input_image_path)\n",
    "\n",
    "# Assuming 'results' is a list, access the first result object\n",
    "result = results[0]\n",
    "\n",
    "# Get the bounding boxes and labels\n",
    "boxes = result.boxes.xyxy.cpu().numpy()  # Get bounding boxes (x1, y1, x2, y2)\n",
    "labels = result.names  # Class names for the predictions\n",
    "\n",
    "# Load the original image\n",
    "image = cv2.imread(input_image_path)\n",
    "\n",
    "# Iterate through the detected boxes and crop the regions with annotations\n",
    "cropped_images = []\n",
    "for i, box in enumerate(boxes):\n",
    "    # Extract coordinates for the bounding box\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    # Crop the region of interest (ROI)\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Convert cropped image to RGB for displaying in matplotlib\n",
    "    cropped_image_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Add the cropped image to the list\n",
    "    cropped_images.append(cropped_image_rgb)\n",
    "    \n",
    "    # Optionally, display cropped images\n",
    "    plt.imshow(cropped_image_rgb)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Optionally save cropped images with unique names\n",
    "for i, cropped_image in enumerate(cropped_images):\n",
    "    cropped_image_path = f\"cropped_{i}.jpg\"\n",
    "    cv2.imwrite(cropped_image_path, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Cropped image saved as {cropped_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-24T16:59:37.545319Z",
     "iopub.status.idle": "2024-12-24T16:59:37.545683Z",
     "shell.execute_reply": "2024-12-24T16:59:37.545546Z",
     "shell.execute_reply.started": "2024-12-24T16:59:37.545529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!yolo task=classify mode=train model=yolov8m-cls.pt data='/kaggle/input/classification-dataset' epochs=10 imgsz=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-24T16:59:37.546671Z",
     "iopub.status.idle": "2024-12-24T16:59:37.547019Z",
     "shell.execute_reply": "2024-12-24T16:59:37.546884Z",
     "shell.execute_reply.started": "2024-12-24T16:59:37.546867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model=YOLO(\"yolov8m-cls.pt\")\n",
    "model.train(data='/kaggle/input/classification-dataset',\n",
    "            epochs=50,\n",
    "            imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-24T16:59:37.548047Z",
     "iopub.status.idle": "2024-12-24T16:59:37.548398Z",
     "shell.execute_reply": "2024-12-24T16:59:37.548230Z",
     "shell.execute_reply.started": "2024-12-24T16:59:37.548214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"yolo_finetuned_cls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-24T16:59:37.550221Z",
     "iopub.status.idle": "2024-12-24T16:59:37.550553Z",
     "shell.execute_reply": "2024-12-24T16:59:37.550423Z",
     "shell.execute_reply.started": "2024-12-24T16:59:37.550407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"/kaggle/working/yolo_finetuned_cls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-24T16:59:37.551600Z",
     "iopub.status.idle": "2024-12-24T16:59:37.551875Z",
     "shell.execute_reply": "2024-12-24T16:59:37.551751Z",
     "shell.execute_reply.started": "2024-12-24T16:59:37.551737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO('/kaggle/working/yolo_finetuned_cls.pt')  # Path to the best classification model\n",
    "\n",
    "# Perform prediction on a single image (classification task)\n",
    "results = model.predict('/kaggle/working/cropped_0.jpg')\n",
    "\n",
    "# Access the first result from the list\n",
    "result = results[0]\n",
    "\n",
    "# Display the classification result\n",
    "result.show()  # Displays the image with the predicted class label\n",
    "\n",
    "# Get the top predicted class and its confidence\n",
    "predicted_class_index = result.probs.top1  # Index of the class with the highest probability\n",
    "predicted_class = result.names[predicted_class_index]  # Get class label\n",
    "confidence = result.probs.top1conf  # Confidence score for the prediction\n",
    "\n",
    "# Print the classification results (class and confidence)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Confidence:\", confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10493123,
     "datasetId": 6304608,
     "sourceId": 10202157,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10583004,
     "datasetId": 6362778,
     "sourceId": 10281999,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10582499,
     "datasetId": 6362437,
     "sourceId": 10281545,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10591420,
     "modelInstanceId": 178182,
     "sourceId": 208998,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
